{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Exploratory Data Analysis'\n",
        "categories: ['EDA']\n",
        "---"
      ],
      "id": "7729914b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_file_names = os.listdir(\"train/\")\n",
        "train_file_names.sort()\n",
        "\n",
        "train_files = []\n",
        "for file in train_file_names:\n",
        "    train_files.append(pd.read_csv(f\"train/{file}\", sep=\";\"))\n",
        "\n",
        "test_file_names = os.listdir(\"test/\")\n",
        "test_file_names.sort()\n",
        "\n",
        "test_files = []\n",
        "for file in test_file_names:\n",
        "    test_files.append(pd.read_csv(f\"test/{file}\", sep=\";\"))\n",
        "\n",
        "test_files[0].head()"
      ],
      "id": "2b78b8f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution of Training Data"
      ],
      "id": "b8198b14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotnine as p9\n",
        "\n",
        "(\n",
        "    p9.ggplot(train_files[0], p9.aes(x=\"Value1\", fill=\"Value1\", color=\"Value1\"))\n",
        "    + p9.geom_density(color=\"red\", alpha=0.1)\n",
        "    + p9.labs(title=\"Distribution of Train File 1\", x=\"Value 1\", y=\"Density\")\n",
        ").show()"
      ],
      "id": "bd904658",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training data is not normally distributed but we suspect its a combination \n",
        "of two normal distributions:\n",
        "- long-term trend\n",
        "- short-term fluctuations\n",
        "\n",
        "We can break up the plot into the specific regions by using a **Fast Fourier Transform**\n"
      ],
      "id": "f6b3e39e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotnine as p9\n",
        "\n",
        "(\n",
        "    p9.ggplot(train_files[0].reset_index(), p9.aes(y=\"Value1\", x=\"index\"))\n",
        "    + p9.geom_line()\n",
        "    + p9.geom_smooth(method=\"loess\")\n",
        ").show()"
      ],
      "id": "6546247a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.fft import fft, ifft, fftfreq\n",
        "\n",
        "fft = fft(train_files[0][\"Value1\"])\n",
        "n = fftfreq(len(train_files[0]))\n",
        "t = train_files[0].index\n",
        "cutoff = 0.05\n",
        "long_term_fft = fft.copy()\n",
        "long_term_fft[np.abs(n) > cutoff] = 0\n",
        "\n",
        "short_term_fft = fft.copy()\n",
        "short_term_fft[np.abs(n) <= cutoff] = 0\n",
        "\n",
        "long_term_signal = np.real(ifft(long_term_fft))\n",
        "short_term_signal = np.real(ifft(short_term_fft))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(t, train_files[0][\"Value1\"], color=\"gray\")\n",
        "plt.title(\"Original Signal\")\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(t, long_term_signal, color=\"green\")\n",
        "plt.title(\"Long-Term\")\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(t, short_term_signal, color=\"orange\")\n",
        "plt.title(\"Short-Term\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "id": "f91b8d81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That didn't work exactly as we wanted.\n",
        "\n",
        "We will try to reconstruct the signal as\n",
        "$$\n",
        "F(x)=asin(b\\theta) + dsin(c\\alpha) \n",
        "$$"
      ],
      "id": "a221fd1c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(train_files[0][\"Value1\"])\n",
        "\n",
        "f = 3 * np.sin(0.02 * np.arange(1, 2000)) + 33\n",
        "\n",
        "plt.plot(f)\n",
        "plt.show()"
      ],
      "id": "e33f8cf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "signal = train_files[0][\"Value1\"]\n",
        "Q1 = np.quantile(signal, 0.25)\n",
        "Q3 = np.quantile(signal, 0.75)\n",
        "plt.plot(signal)\n",
        "plt.axhline(Q1)\n",
        "plt.axhline(Q3)\n",
        "plt.show()"
      ],
      "id": "e4a63bc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution of Testing Data"
      ],
      "id": "8b05a1cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "signal = test_files[0].reset_index()\n",
        "\n",
        "(p9.ggplot(signal, p9.aes(x=\"Value1\")) + p9.geom_density()).show()"
      ],
      "id": "967894d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "The training data cannot be used to predict the testing data for two reasons:\n",
        "\n",
        "1. The training data is 2000 observations per file totaling 20,000 compared to \n",
        "    the testing data which is 10,000 per file totaling 100,000\n",
        "\n",
        "2. The training data does not follow the same distribution as the testing data\n",
        "    meaning a statistical model which makes an assumption about the distribution\n",
        "    isn't appropriate\n",
        "\n",
        "The biggest problem is that the training data is so much less than the testing\n",
        "data.\n",
        "\n",
        "If we combine the files together, the train-test split won't be 80% and 20%\n",
        "for train and test respectively but will be the other way around i.e:\n",
        "\n",
        "- train = 17% of all data\n",
        "- test = 83% of all data\n",
        "\n",
        "To balance it properly would require sampling strategies but the goal is \n",
        "anomaly detection so oversampling to balance anomalies would add a lot of noise\n",
        "to the data.\n",
        "\n",
        "The training data also has no anomalies to detect so the algorithm won't learn\n",
        "from the data itself."
      ],
      "id": "7f0deccc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/alex/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}