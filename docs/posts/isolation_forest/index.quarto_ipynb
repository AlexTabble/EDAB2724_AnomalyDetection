{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Isolation Forest'\n",
        "html:\n",
        "  theme: darkly\n",
        "categories: ['Model']\n",
        "---"
      ],
      "id": "34c33522"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_file_names = os.listdir(\"train/\")\n",
        "train_file_names.sort()\n",
        "\n",
        "train_files = []\n",
        "for file in train_file_names:\n",
        "    train_files.append(pd.read_csv(f\"train/{file}\", sep=\";\"))\n",
        "\n",
        "test_file_names = os.listdir(\"test/\")\n",
        "test_file_names.sort()\n",
        "\n",
        "test_files = []\n",
        "for file in test_file_names:\n",
        "    test_files.append(pd.read_csv(f\"test/{file}\", sep=\";\"))\n",
        "\n",
        "test_files[0].head()"
      ],
      "id": "e24d3603",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Student EDA\n",
        "Use this cell to explore the signal (e.g., plot, summary stats)."
      ],
      "id": "5b5a1272"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# STUDENT EDA\n",
        "try:\n",
        "    df = test_files[0]\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print('EDA note: run the original data-loading cells first (the ones that populate train_files/test_files).')"
      ],
      "id": "30240e7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **The Model**"
      ],
      "id": "9e3f16aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numba import njit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"Determinant has increased; this should not happen\"\n",
        ")\n",
        "\n",
        "@njit\n",
        "def create_windows_numba(series, window_size):\n",
        "    n_windows = len(series) - window_size + 1\n",
        "    windows = np.empty((n_windows, window_size), dtype=np.float32)\n",
        "    for i in range(n_windows):\n",
        "        windows[i, :] = series[i : i + window_size]\n",
        "    return windows\n",
        "\n",
        "@njit\n",
        "def normalize_scores(scores):\n",
        "    mn = np.min(scores)\n",
        "    mx = np.max(scores)\n",
        "    return (scores - mn) / (mx - mn + 1e-8)\n",
        "\n",
        "\n",
        "class AnomalyDetectionModel:\n",
        "    def __init__(self, window_size=30, contamination=0.01):\n",
        "        self.window_size = window_size\n",
        "        self.offset = window_size // 2\n",
        "        self.contamination = contamination\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        self.models = {\n",
        "            'IsolationForest': IsolationForest(contamination=contamination, random_state=42),\n",
        "            'OneClassSVM': OneClassSVM(kernel='rbf', gamma='scale', nu=contamination),\n",
        "            'EllipticEnvelope': EllipticEnvelope(contamination=contamination,\n",
        "                                                 support_fraction=0.75,\n",
        "                                                 random_state=42),\n",
        "        }\n",
        "\n",
        "        self.use_lof = True\n",
        "        self.lof_model = LocalOutlierFactor(n_neighbors=20,\n",
        "                                            contamination=contamination,\n",
        "                                            novelty=True)\n",
        "        self.full_anomaly_mask = None\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray = None):\n",
        "        self.train_windows = self._create_windows(X)\n",
        "        self.scaled_train_windows = self.scaler.fit_transform(self.train_windows)\n",
        "        for model in self.models.values():\n",
        "            model.fit(self.scaled_train_windows)\n",
        "        if self.use_lof:\n",
        "            self.lof_model.fit(self.scaled_train_windows)\n",
        "\n",
        "    def predict(self, X: np.ndarray):\n",
        "\n",
        "        test_windows = self._create_windows(X)\n",
        "        scaled = self.scaler.transform(test_windows)\n",
        "\n",
        "\n",
        "        all_scores = []\n",
        "        for model in self.models.values():\n",
        "            if hasattr(model, \"decision_function\"):\n",
        "                s = model.decision_function(scaled)\n",
        "                all_scores.append(normalize_scores(s))\n",
        "            else:\n",
        "                preds = model.predict(scaled)\n",
        "                all_scores.append(np.where(preds == -1, 0.0, 1.0))\n",
        "\n",
        "        if self.use_lof:\n",
        "            lof_s = self.lof_model.decision_function(scaled)\n",
        "            all_scores.append(normalize_scores(lof_s))\n",
        "\n",
        "        avg_scores = np.mean(np.stack(all_scores, axis=0), axis=0)\n",
        "        thresh = np.percentile(avg_scores, self.contamination * 100)\n",
        "        mask = np.zeros(len(X), dtype=int)\n",
        "        mask[self.offset : self.offset + len(avg_scores)] = (avg_scores <= thresh).astype(int)\n",
        "        self.full_anomaly_mask = mask\n",
        "        idx = np.argmin(avg_scores)\n",
        "        return idx + self.offset\n",
        "    def _create_windows(self, series: np.ndarray):\n",
        "        return create_windows_numba(series, self.window_size)"
      ],
      "id": "f8b861dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation\n",
        "\n",
        "This pipeline works on the idea that:\n",
        "\n",
        "        1) it builds upon sliding windows\n",
        "        2) gathers normalised anomaly scores from each sub-model and uses them\n",
        "        3) averages the anomaly scores\n",
        "        4) computes a binary mask by thresholding at the 1st percentile so that it can compare outputs\n",
        "        5) stores self.full_anomaly_mask (same length as the placeholder value)\n",
        "        6) returns the single index of the lowest‐score window center which closes the loop on the sliding window idea\n",
        "\n",
        "\n",
        "## **STUDENT TODO — Implement your anomaly detector**\n",
        "Implement Machine Learning/ Statistical models or both. Use the test_files (test series) to train your models and list of anomaly index range for example Anomaly 1:   2001-2005\n",
        "Anomaly 2:   2010-2012\n",
        "\n",
        "\n",
        "**Constraints**\n",
        "\n",
        "- Keep it efficient; we will run this over 10 datasets and additional novel datasets in class.\n",
        "\n",
        "\n",
        "#EDA on given model"
      ],
      "id": "b8238a33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Normalization\n",
        "scaler = StandardScaler()"
      ],
      "id": "7b258007",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Reshape\n",
        "rx = df['Value1'].values.reshape(-1,1)\n",
        "\n",
        "np_scaled = scaler.fit_transform(rx)\n",
        "data = pd.DataFrame(np_scaled)"
      ],
      "id": "628c6339",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "id": "deb39903",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def detect_peaks_anomalies(x, min_height=None, distance=20):\n",
        "    \"\"\"Peak detection for spike anomalies - WITH StandardScaler\"\"\"\n",
        "    from scipy.signal import find_peaks\n",
        "\n",
        "    # Normalize using StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    x_normalized = scaler.fit_transform(x.reshape(-1, 1)).flatten()\n",
        "\n",
        "    if min_height is None:\n",
        "        min_height = 3.0  # Now in standard deviation units\n",
        "\n",
        "    peaks, _ = find_peaks(x_normalized, height=min_height, distance=distance)\n",
        "    neg_peaks, _ = find_peaks(-x_normalized, height=min_height, distance=distance)\n",
        "\n",
        "    return list(peaks) + list(neg_peaks)\n",
        "\n",
        "def detect_change_point_anomalies(x, window_size=50):\n",
        "    \"\"\"Detect anomalies based on distribution changes - WITH StandardScaler\"\"\"\n",
        "    anomalies = []\n",
        "\n",
        "    # Normalize using StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    x_normalized = scaler.fit_transform(x.reshape(-1, 1)).flatten()\n",
        "\n",
        "    for i in range(window_size, len(x_normalized) - window_size):\n",
        "        before_window = x_normalized[i-window_size:i]\n",
        "        after_window = x_normalized[i:i+window_size]\n",
        "\n",
        "        # Statistical test on standardized data\n",
        "        mean_diff = np.abs(np.mean(after_window) - np.mean(before_window))\n",
        "        std_before = np.std(before_window)\n",
        "\n",
        "        # Threshold in standard deviation units\n",
        "        if std_before > 0 and mean_diff > 3.0:  # 2 standard deviations\n",
        "            anomalies.append(i)\n",
        "\n",
        "    return anomalies"
      ],
      "id": "f5096d56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Implement your anomaly detector/ detectors. You can edit this or use your own\n",
        "import numpy as np\n",
        "\n",
        "def student_detect_anomalies(series: np.ndarray) -> list:\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        series: 1D array-like of floats (test series)\n",
        "    Output:\n",
        "        List of (start, end) index pairs (0-based, end exclusive) for anomaly ranges.\n",
        "    \"\"\"\n",
        "    x = np.asarray(series, dtype=float)\n",
        "    n = len(x)\n",
        "    if n == 0:\n",
        "        return []\n",
        "\n",
        "    # Rolling mean/std z-score on a smoothed series\n",
        "    # Smooth to get residuals\n",
        "    w_smooth = 51\n",
        "    k = np.ones(w_smooth) / w_smooth\n",
        "    smooth = np.convolve(x, k, mode='same')\n",
        "    resid = x - smooth\n",
        "\n",
        "    # 2) Rolling mean/std using convolution (no extra libs)\n",
        "    w = 61  # odd; students may tune\n",
        "    kw = np.ones(w) / w\n",
        "    mu = np.convolve(resid, kw, mode='same')\n",
        "    mu2 = np.convolve(resid*resid, kw, mode='same')\n",
        "    var = np.maximum(mu2 - mu*mu, 1e-8)\n",
        "    sigma = np.sqrt(var)\n",
        "    z = np.abs((resid - mu) / (sigma + 1e-8))\n",
        "\n",
        "\n",
        "\n",
        "print('anomalies identified.')"
      ],
      "id": "f2a6ec90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Evaluation**\n",
        " The higher the accuracy the better."
      ],
      "id": "4c648313"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "for train, test in zip(train_files, test_files):\n",
        "    model = AnomalyDetectionModel()\n",
        "\n",
        "    model.fit(train.Value1.to_numpy().flatten(), train.Labels.to_numpy().flatten())\n",
        "\n",
        "    prediction_index = model.predict(test.Value1.to_numpy().flatten())\n",
        "\n",
        "\n",
        "    if (test.loc[prediction_index, \"Labels\"] == 1):\n",
        "        correct += 1\n",
        "\n",
        "print(f\"Total score: {correct}%\")"
      ],
      "id": "aa8caf1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use other various evaluation metrics applicable to your models."
      ],
      "id": "a7fbcb71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#**Limitations**\n",
        "While the ensemble sliding-window model seems to be a good fir,it does have some downsides.\n",
        "\n",
        "##**Computational Cost**:\n",
        "Because the model creates overlapping windows and runs multiple anomaly detection algorithms on each window, it can be computationally intensive—especially for long time series or when using a small window size (which results in many windows).\n",
        "\n",
        "##**This means it will require increased memory usage**\n",
        "\n",
        "##**It also means longer runtime compared to a single-model approach**\n",
        "\n",
        "It may not be suitable for very large datasets or real-time applications unless optimized or run on powerful hardware and there are some constructive bial issues that still need to be tested.\n",
        "\n",
        "**_For faster experiments, we could use a larger window size, downsampling the data, or disabling one or more models in the ensemble, but for this we need testing_**\n",
        "\n",
        "\n",
        "# **Visualisation of the anomalies**  \n",
        "\n",
        "Reuse this code to visualize the anomalies."
      ],
      "id": "a4071914"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def visualize_anomaly_detection(test_df, model, file_idx=None):\n",
        "    \"\"\"\n",
        "    Visualizes:\n",
        "    - Signal (black)\n",
        "    - Ground truth anomalies (red)\n",
        "    - Predicted anomalies (green)\n",
        "    - Most anomalous index (blue dot)\n",
        "    \"\"\"\n",
        "    series = test_df['Value1'].to_numpy()\n",
        "    true_mask = test_df['Labels'].to_numpy().astype(bool)\n",
        "    pred_mask = model.full_anomaly_mask.astype(bool)\n",
        "    most_anomalous = np.argmin(pred_mask) if pred_mask.any() else None\n",
        "    pred_index = model.predict(series)  # triggers .full_anomaly_mask\n",
        "\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.plot(series, color='black', lw=1, label='Signal')\n",
        "\n",
        "    if pred_mask.any():\n",
        "        plt.fill_between(np.arange(len(series)), series,\n",
        "                         where=pred_mask, color='green', alpha=0.3,\n",
        "                         label='Predicted Anomaly')\n",
        "\n",
        "    if true_mask.any():\n",
        "        plt.fill_between(np.arange(len(series)), series,\n",
        "                         where=true_mask, color='red', alpha=0.3,\n",
        "                         label='True Anomaly')\n",
        "\n",
        "    if 0 <= pred_index < len(series):\n",
        "        plt.scatter(pred_index, series[pred_index], color='blue', s=50, label='Most Anomalous Point')\n",
        "\n",
        "    title = f\"File {file_idx}\" if file_idx is not None else \"Anomaly Detection\"\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -- Loop over all files and visualize each --\n",
        "for idx, (train, test) in enumerate(zip(train_files, test_files), 1):\n",
        "    model = AnomalyDetectionModel(window_size=30, contamination=0.01)\n",
        "    model.fit(train['Value1'].to_numpy(), train['Labels'].to_numpy())\n",
        "    model.predict(test['Value1'].to_numpy())  # sets .full_anomaly_mask\n",
        "    visualize_anomaly_detection(test, model, file_idx=idx)"
      ],
      "id": "b2c710c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#EDA"
      ],
      "id": "bebdd233"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "id": "9e444fbd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df.shape)\n",
        "\n",
        "print(\"Data Types\", df.dtypes)\n",
        "print(\"Descriptive stats:\", df['Value1'].describe())\n",
        "\n",
        "missing_vals = df['Value1'].isna().sum()\n",
        "print(f\"\\nMissing Total values: {missing_vals}\")"
      ],
      "id": "6b4ef582",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "df.describe()"
      ],
      "id": "9197f149",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "# Show histograms - all variables except for the identifier\n",
        "df.hist(bins = 20, figsize =(20, 10))\n",
        "plt.show()"
      ],
      "id": "31afff78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comprehensive EDA with statistical analysis and visualizations\n",
        "\n",
        "Proper preprocessing using StandardScaler\n",
        "\n",
        "Feature engineering with rolling window statistics\n",
        "\n",
        "Isolation Forest model with configurable parameters\n",
        "\n",
        "Range-based detection that groups consecutive anomalies\n",
        "\n",
        "Comprehensive evaluation with precision, recall, and F1-score\n",
        "\n",
        "Visualization to compare true vs predicted anomalies"
      ],
      "id": "a505a58b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Enhanced Isolation Forest Anomaly Detector with 10-anomaly target\n",
        "class IsolationForestAnomalyDetector:\n",
        "    def __init__(self, target_anomalies=10, contamination_range=(0.01, 0.2), random_state=42):\n",
        "        self.target_anomalies = target_anomalies\n",
        "        self.contamination_range = contamination_range\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.anomaly_windows = []\n",
        "        self.optimal_contamination = None\n",
        "\n",
        "    def create_features(self, series, window_size=50):\n",
        "        \"\"\"Create rolling window features for better anomaly detection\"\"\"\n",
        "        series = np.array(series).reshape(-1, 1)\n",
        "\n",
        "        # Basic statistical features\n",
        "        features = []\n",
        "\n",
        "        # Original value\n",
        "        features.append(series)\n",
        "\n",
        "        # Rolling statistics\n",
        "        for window in [10, 20, 50]:\n",
        "            if len(series) >= window:\n",
        "                # Rolling mean\n",
        "                roll_mean = pd.Series(series.flatten()).rolling(window=window, center=True).mean().values.reshape(-1, 1)\n",
        "                features.append(roll_mean)\n",
        "\n",
        "                # Rolling standard deviation\n",
        "                roll_std = pd.Series(series.flatten()).rolling(window=window, center=True).std().values.reshape(-1, 1)\n",
        "                features.append(roll_std)\n",
        "\n",
        "                # Difference from rolling mean\n",
        "                diff_from_mean = series - roll_mean\n",
        "                features.append(diff_from_mean)\n",
        "\n",
        "        # Add more features for better detection\n",
        "        # Z-score\n",
        "        z_score = (series - np.mean(series)) / np.std(series)\n",
        "        features.append(z_score)\n",
        "\n",
        "        # Combine all features\n",
        "        feature_matrix = np.hstack([f for f in features if f is not None and not np.any(np.isnan(f))])\n",
        "\n",
        "        # Handle NaN values that might occur from rolling operations\n",
        "        feature_matrix = np.nan_to_num(feature_matrix)\n",
        "\n",
        "        return feature_matrix\n",
        "\n",
        "    def find_anomaly_ranges(self, predictions, min_consecutive=3):\n",
        "        \"\"\"Convert point anomalies to ranges\"\"\"\n",
        "        anomaly_indices = np.where(predictions == -1)[0]\n",
        "\n",
        "        if len(anomaly_indices) == 0:\n",
        "            return []\n",
        "\n",
        "        # Group consecutive anomalies\n",
        "        ranges = []\n",
        "        start = anomaly_indices[0]\n",
        "        end = anomaly_indices[0]\n",
        "        count = 1\n",
        "\n",
        "        for i in range(1, len(anomaly_indices)):\n",
        "            if anomaly_indices[i] == anomaly_indices[i-1] + 1:\n",
        "                end = anomaly_indices[i]\n",
        "                count += 1\n",
        "            else:\n",
        "                # Only keep ranges with minimum consecutive anomalies\n",
        "                if count >= min_consecutive:\n",
        "                    ranges.append((start, end))\n",
        "                start = anomaly_indices[i]\n",
        "                end = anomaly_indices[i]\n",
        "                count = 1\n",
        "\n",
        "        # Add the last range\n",
        "        if count >= min_consecutive:\n",
        "            ranges.append((start, end))\n",
        "\n",
        "        return ranges\n",
        "\n",
        "    def optimize_contamination(self, X):\n",
        "        \"\"\"Find optimal contamination parameter to get close to target anomalies\"\"\"\n",
        "        best_contamination = self.contamination_range[0]\n",
        "        best_diff = float('inf')\n",
        "        best_predictions = None\n",
        "\n",
        "        # Test multiple contamination values\n",
        "        contamination_values = np.linspace(self.contamination_range[0], self.contamination_range[1], 20)\n",
        "\n",
        "        for contamination in contamination_values:\n",
        "            # Create features\n",
        "            X_features = self.create_features(X)\n",
        "            X_scaled = self.scaler.fit_transform(X_features)\n",
        "\n",
        "            # Train Isolation Forest\n",
        "            model = IsolationForest(\n",
        "                contamination=contamination,\n",
        "                random_state=self.random_state,\n",
        "                n_estimators=100\n",
        "            )\n",
        "            model.fit(X_scaled)\n",
        "\n",
        "            # Predict anomalies\n",
        "            predictions = model.predict(X_scaled)\n",
        "            n_anomalies = np.sum(predictions == -1)\n",
        "\n",
        "            # Calculate how close we are to target\n",
        "            diff = abs(n_anomalies - self.target_anomalies)\n",
        "\n",
        "            if diff < best_diff:\n",
        "                best_diff = diff\n",
        "                best_contamination = contamination\n",
        "                best_predictions = predictions\n",
        "\n",
        "        self.optimal_contamination = best_contamination\n",
        "        return best_predictions, best_contamination\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"Fit the model on training data with optimized contamination\"\"\"\n",
        "        # Optimize contamination parameter\n",
        "        predictions, optimal_contamination = self.optimize_contamination(X)\n",
        "\n",
        "        # Create features\n",
        "        X_features = self.create_features(X)\n",
        "\n",
        "        # Scale the features\n",
        "        X_scaled = self.scaler.fit_transform(X_features)\n",
        "\n",
        "        # Train final Isolation Forest with optimal contamination\n",
        "        self.model = IsolationForest(\n",
        "            contamination=optimal_contamination,\n",
        "            random_state=self.random_state,\n",
        "            n_estimators=100\n",
        "        )\n",
        "        self.model.fit(X_scaled)\n",
        "\n",
        "        # Store anomaly windows\n",
        "        self.anomaly_windows = self.find_anomaly_ranges(predictions)\n",
        "\n",
        "        print(f\"Optimal contamination: {optimal_contamination:.4f}\")\n",
        "        print(f\"Number of anomaly points detected: {np.sum(predictions == -1)}\")\n",
        "        print(f\"Number of anomaly ranges: {len(self.anomaly_windows)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict anomalies on test data\"\"\"\n",
        "        # Create features\n",
        "        X_features = self.create_features(X)\n",
        "\n",
        "        # Scale the features\n",
        "        X_scaled = self.scaler.transform(X_features)\n",
        "\n",
        "        # Predict anomalies\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "\n",
        "        # Convert to binary (1 = normal, -1 = anomaly)\n",
        "        binary_predictions = np.where(predictions == 1, 0, 1)\n",
        "\n",
        "        # Find anomaly ranges\n",
        "        self.anomaly_windows = self.find_anomaly_ranges(predictions)\n",
        "\n",
        "        return binary_predictions\n",
        "\n",
        "# Enhanced student anomaly detector with 10-anomaly target\n",
        "def student_detect_anomalies(series: np.ndarray) -> list:\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    series: 1D array-like of floats (test series)\n",
        "\n",
        "    Output:\n",
        "    List of (start, end) index pairs (0-based, end inclusive) for anomaly ranges.\n",
        "    \"\"\"\n",
        "    x = np.asarray(series, dtype=float)\n",
        "    n = len(x)\n",
        "\n",
        "    if n == 0:\n",
        "        return []\n",
        "\n",
        "    # Initialize and fit the Isolation Forest detector with 10-anomaly target\n",
        "    detector = IsolationForestAnomalyDetector(\n",
        "        target_anomalies=10,\n",
        "        contamination_range=(0.005, 0.3),  # Wider range to find optimal value\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit on the test series\n",
        "    detector.fit(x)\n",
        "\n",
        "    # Return the detected anomaly ranges\n",
        "    return detector.anomaly_windows\n",
        "\n",
        "# Enhanced evaluation function with detailed accuracy metrics\n",
        "def evaluate_anomaly_detection_enhanced(true_ranges, predicted_ranges, tolerance=5, target_anomalies=10):\n",
        "    \"\"\"\n",
        "    Enhanced evaluation with accuracy metrics and target-based scoring\n",
        "    \"\"\"\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "\n",
        "    # Convert true ranges from labels\n",
        "    true_anomaly_segments = []\n",
        "    for true_range in true_ranges:\n",
        "        true_anomaly_segments.append((true_range[0], true_range[1]))\n",
        "\n",
        "    # Check each predicted range against true ranges\n",
        "    matched_true = set()\n",
        "\n",
        "    for pred_start, pred_end in predicted_ranges:\n",
        "        matched = False\n",
        "        for i, (true_start, true_end) in enumerate(true_anomaly_segments):\n",
        "            # Check if predicted range overlaps with true range within tolerance\n",
        "            if (pred_start <= true_end + tolerance and pred_end >= true_start - tolerance):\n",
        "                if i not in matched_true:\n",
        "                    true_positives += 1\n",
        "                    matched_true.add(i)\n",
        "                    matched = True\n",
        "                    break\n",
        "\n",
        "        if not matched:\n",
        "            false_positives += 1\n",
        "\n",
        "    false_negatives = len(true_anomaly_segments) - len(matched_true)\n",
        "\n",
        "    # Calculate standard metrics\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / len(true_anomaly_segments) if len(true_anomaly_segments) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Calculate accuracy metrics\n",
        "    total_predictions = len(predicted_ranges)\n",
        "    target_accuracy = 1 - min(abs(total_predictions - target_anomalies) / target_anomalies, 1.0)\n",
        "\n",
        "    # Combined score (weighted average of F1 and target accuracy)\n",
        "    combined_score = 0.7 * f1 + 0.3 * target_accuracy\n",
        "\n",
        "    # Detection success (1 if at least one true positive, 0 otherwise)\n",
        "    detection_success = 1 if true_positives > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'true_positives': true_positives,\n",
        "        'false_positives': false_positives,\n",
        "        'false_negatives': false_negatives,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'target_accuracy': target_accuracy,\n",
        "        'combined_score': combined_score,\n",
        "        'detection_success': detection_success,\n",
        "        'total_predicted_ranges': total_predictions,\n",
        "        'total_true_ranges': len(true_anomaly_segments)\n",
        "    }\n",
        "\n",
        "# Enhanced visualization with accuracy information\n",
        "def visualize_anomaly_detection_with_accuracy(test_df, predicted_ranges, metrics, file_idx=None):\n",
        "    \"\"\"Visualize the anomaly detection results with accuracy information\"\"\"\n",
        "    series = test_df['Value'].values if 'Value' in test_df.columns else test_df.iloc[:, 0].values\n",
        "    true_labels = test_df['Labels'].values if 'Labels' in test_df.columns else test_df.iloc[:, 1].values\n",
        "    true_mask = true_labels.astype(bool)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # Plot the signal\n",
        "    plt.plot(series, color='black', linewidth=1, label='Signal')\n",
        "\n",
        "    # Plot true anomalies\n",
        "    if true_mask.any():\n",
        "        plt.fill_between(np.arange(len(series)), np.min(series), np.max(series),\n",
        "                        where=true_mask, color='red', alpha=0.3, label='True Anomalies')\n",
        "\n",
        "    # Plot predicted anomalies\n",
        "    for start, end in predicted_ranges:\n",
        "        plt.axvspan(start, end, alpha=0.3, color='green', label='Predicted Anomalies' if start == predicted_ranges[0][0] else \"\")\n",
        "\n",
        "    # Add accuracy information to title\n",
        "    title = f'File {file_idx} - ' if file_idx is not None else ''\n",
        "    title += f'Anomaly Detection (F1: {metrics[\"f1_score\"]:.3f}, Target Acc: {metrics[\"target_accuracy\"]:.3f})'\n",
        "    title += f'\\nTP: {metrics[\"true_positives\"]}, FP: {metrics[\"false_positives\"]}, FN: {metrics[\"false_negatives\"]}'\n",
        "    title += f', Predicted: {metrics[\"total_predicted_ranges\"]}, True: {metrics[\"total_true_ranges\"]}'\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Enhanced main evaluation loop\n",
        "print(\"Starting Enhanced Isolation Forest Anomaly Detection Evaluation\")\n",
        "print(\"TARGET: Detect approximately 10 anomalies in each of the 10 datasets\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "total_correct = 0\n",
        "total_files = len(test_files)\n",
        "all_metrics = []\n",
        "detailed_results = []\n",
        "\n",
        "for idx, test_df in enumerate(test_files):\n",
        "    print(f\"\\n--- Processing File {idx} ---\")\n",
        "\n",
        "    try:\n",
        "        # Extract series and labels\n",
        "        series = test_df['Value'].values if 'Value' in test_df.columns else test_df.iloc[:, 0].values\n",
        "        labels = test_df['Labels'].values if 'Labels' in test_df.columns else test_df.iloc[:, 1].values\n",
        "\n",
        "        # Get true anomaly ranges\n",
        "        true_ranges = extract_true_anomaly_ranges(labels)\n",
        "        print(f\"True anomaly ranges: {true_ranges}\")\n",
        "        print(f\"Number of true anomaly segments: {len(true_ranges)}\")\n",
        "\n",
        "        # Detect anomalies using enhanced student's function\n",
        "        predicted_ranges = student_detect_anomalies(series)\n",
        "        print(f\"Predicted anomaly ranges: {predicted_ranges}\")\n",
        "        print(f\"Number of predicted anomaly segments: {len(predicted_ranges)}\")\n",
        "\n",
        "        # Evaluate performance with target-based metrics\n",
        "        metrics = evaluate_anomaly_detection_enhanced(true_ranges, predicted_ranges, target_anomalies=10)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "        # Store detailed results\n",
        "        detailed_results.append({\n",
        "            'file_idx': idx,\n",
        "            'true_ranges': true_ranges,\n",
        "            'predicted_ranges': predicted_ranges,\n",
        "            'metrics': metrics\n",
        "        })\n",
        "\n",
        "        # Count correct detections (at least one true positive)\n",
        "        correct_this_file = metrics['detection_success']\n",
        "        total_correct += correct_this_file\n",
        "\n",
        "        print(f\"True Positives: {metrics['true_positives']}\")\n",
        "        print(f\"False Positives: {metrics['false_positives']}\")\n",
        "        print(f\"False Negatives: {metrics['false_negatives']}\")\n",
        "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "        print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
        "        print(f\"Target Accuracy: {metrics['target_accuracy']:.4f}\")\n",
        "        print(f\"Combined Score: {metrics['combined_score']:.4f}\")\n",
        "        print(f\"File {idx} Detection Success: {correct_this_file}/1\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {idx}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Add zero metrics for failed files\n",
        "        all_metrics.append({\n",
        "            'true_positives': 0,\n",
        "            'false_positives': 0,\n",
        "            'false_negatives': len(true_ranges) if 'true_ranges' in locals() else 0,\n",
        "            'precision': 0,\n",
        "            'recall': 0,\n",
        "            'f1_score': 0,\n",
        "            'target_accuracy': 0,\n",
        "            'combined_score': 0,\n",
        "            'detection_success': 0,\n",
        "            'total_predicted_ranges': 0,\n",
        "            'total_true_ranges': len(true_ranges) if 'true_ranges' in locals() else 0\n",
        "        })\n",
        "\n",
        "# Calculate overall scores with enhanced metrics\n",
        "overall_precision = np.mean([m['precision'] for m in all_metrics])\n",
        "overall_recall = np.mean([m['recall'] for m in all_metrics])\n",
        "overall_f1 = np.mean([m['f1_score'] for m in all_metrics])\n",
        "overall_target_accuracy = np.mean([m['target_accuracy'] for m in all_metrics])\n",
        "overall_combined_score = np.mean([m['combined_score'] for m in all_metrics])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL ENHANCED RESULTS FOR ALL TEST FILES\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total files processed: {total_files}\")\n",
        "print(f\"Total correct files: {total_correct}/{total_files}\")\n",
        "print(f\"Detection Accuracy: {(total_correct/total_files)*100:.2f}%\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
        "print(f\"Overall Target Accuracy: {overall_target_accuracy:.4f}\")\n",
        "print(f\"Overall Combined Score: {overall_combined_score:.4f}\")\n",
        "\n",
        "# Enhanced detailed results display\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DETAILED ENHANCED RESULTS BY FILE\")\n",
        "print(\"=\" * 70)\n",
        "for result in detailed_results:\n",
        "    m = result['metrics']\n",
        "    print(f\"\\nFile {result['file_idx']}:\")\n",
        "    print(f\"  True Ranges: {result['true_ranges']} (count: {len(result['true_ranges'])})\")\n",
        "    print(f\"  Predicted Ranges: {result['predicted_ranges']} (count: {len(result['predicted_ranges'])})\")\n",
        "    print(f\"  Precision: {m['precision']:.4f}\")\n",
        "    print(f\"  Recall: {m['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {m['f1_score']:.4f}\")\n",
        "    print(f\"  Target Accuracy: {m['target_accuracy']:.4f}\")\n",
        "    print(f\"  Combined Score: {m['combined_score']:.4f}\")\n",
        "    print(f\"  Detection Success: {m['detection_success']}/1\")\n",
        "\n",
        "# Enhanced visualization for ALL files\n",
        "print(\"\\nVisualizing enhanced results for ALL files...\")\n",
        "for idx, test_df in enumerate(test_files):\n",
        "    try:\n",
        "        series = test_df['Value'].values if 'Value' in test_df.columns else test_df.iloc[:, 0].values\n",
        "        labels = test_df['Labels'].values if 'Labels' in test_df.columns else test_df.iloc[:, 1].values\n",
        "        true_ranges = extract_true_anomaly_ranges(labels)\n",
        "        predicted_ranges = student_detect_anomalies(series)\n",
        "        metrics = evaluate_anomaly_detection_enhanced(true_ranges, predicted_ranges, target_anomalies=10)\n",
        "        visualize_anomaly_detection_with_accuracy(test_df, predicted_ranges, metrics, file_idx=idx)\n",
        "    except Exception as e:\n",
        "        print(f\"Error visualizing file {idx}: {e}\")\n",
        "\n",
        "# Create comprehensive summary visualization\n",
        "print(\"\\nCreating comprehensive performance summary...\")\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Overall performance metrics\n",
        "plt.subplot(3, 3, 1)\n",
        "metrics_names = ['Precision', 'Recall', 'F1-Score', 'Target Acc', 'Combined']\n",
        "metrics_values = [overall_precision, overall_recall, overall_f1, overall_target_accuracy, overall_combined_score]\n",
        "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
        "\n",
        "plt.bar(metrics_names, metrics_values, color=colors)\n",
        "plt.title('Overall Performance Metrics')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "for i, v in enumerate(metrics_values):\n",
        "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Plot 2: Per-file F1 scores\n",
        "plt.subplot(3, 3, 2)\n",
        "file_indices = list(range(total_files))\n",
        "f1_scores = [m['f1_score'] for m in all_metrics]\n",
        "plt.bar(file_indices, f1_scores, color='orange', alpha=0.7)\n",
        "plt.axhline(y=overall_f1, color='red', linestyle='--', label=f'Average: {overall_f1:.3f}')\n",
        "plt.title('F1-Score by File')\n",
        "plt.xlabel('File Index')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "\n",
        "# Plot 3: Per-file target accuracy\n",
        "plt.subplot(3, 3, 3)\n",
        "target_accuracies = [m['target_accuracy'] for m in all_metrics]\n",
        "plt.bar(file_indices, target_accuracies, color='purple', alpha=0.7)\n",
        "plt.axhline(y=overall_target_accuracy, color='red', linestyle='--', label=f'Average: {overall_target_accuracy:.3f}')\n",
        "plt.title('Target Accuracy by File')\n",
        "plt.xlabel('File Index')\n",
        "plt.ylabel('Target Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "\n",
        "# Plot 4: Detection summary\n",
        "plt.subplot(3, 3, 4)\n",
        "total_tp = sum([m['true_positives'] for m in all_metrics])\n",
        "total_fp = sum([m['false_positives'] for m in all_metrics])\n",
        "total_fn = sum([m['false_negatives'] for m in all_metrics])\n",
        "\n",
        "detection_types = ['True Positives', 'False Positives', 'False Negatives']\n",
        "detection_counts = [total_tp, total_fp, total_fn]\n",
        "colors = ['green', 'red', 'orange']\n",
        "\n",
        "plt.bar(detection_types, detection_counts, color=colors)\n",
        "plt.title('Overall Detection Summary')\n",
        "plt.xticks(rotation=45)\n",
        "for i, v in enumerate(detection_counts):\n",
        "    plt.text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
        "\n",
        "# Plot 5: File-wise detection success\n",
        "plt.subplot(3, 3, 5)\n",
        "file_scores = [m['detection_success'] for m in all_metrics]\n",
        "colors = ['red' if score == 0 else 'green' for score in file_scores]\n",
        "plt.bar(file_indices, file_scores, color=colors)\n",
        "plt.title('File-wise Detection Success (1=Success, 0=Failure)')\n",
        "plt.xlabel('File Index')\n",
        "plt.ylabel('Detection Success')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Plot 6: Predicted vs Target ranges\n",
        "plt.subplot(3, 3, 6)\n",
        "predicted_counts = [m['total_predicted_ranges'] for m in all_metrics]\n",
        "target_line = [10] * total_files  # Target of 10 anomalies per file\n",
        "\n",
        "plt.plot(file_indices, predicted_counts, 'bo-', label='Predicted Ranges', linewidth=2)\n",
        "plt.plot(file_indices, target_line, 'r--', label='Target (10)', linewidth=2)\n",
        "plt.title('Predicted vs Target Anomaly Ranges')\n",
        "plt.xlabel('File Index')\n",
        "plt.ylabel('Number of Ranges')\n",
        "plt.legend()\n",
        "\n",
        "# Plot 7: Combined score by file\n",
        "plt.subplot(3, 3, 7)\n",
        "combined_scores = [m['combined_score'] for m in all_metrics]\n",
        "plt.bar(file_indices, combined_scores, color='orange', alpha=0.7)\n",
        "plt.axhline(y=overall_combined_score, color='red', linestyle='--', label=f'Average: {overall_combined_score:.3f}')\n",
        "plt.title('Combined Score by File')\n",
        "plt.xlabel('File Index')\n",
        "plt.ylabel('Combined Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEnhanced anomaly detection completed for all test files!\")\n",
        "print(f\"Final Summary: {total_correct}/{total_files} files successfully detected anomalies\")\n",
        "print(f\"Overall performance score: {overall_combined_score:.4f}\")"
      ],
      "id": "309b05eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Isolation Forest and Z-score Hybrid Model\n",
        "\n",
        "###Data Processing & Feature Engineering\n",
        "Extracts true anomaly ranges from label arrays using extract_true_anomaly_ranges()\n",
        "\n",
        "Creates enhanced features including:\n",
        "\n",
        "Original time series values\n",
        "\n",
        "Multiple rolling window statistics (mean, std, min, max) across different window sizes\n",
        "\n",
        "Z-scores based on rolling statistics\n",
        "\n",
        "Global statistics (mean, std, z-score)\n",
        "\n",
        "Rate of change and second derivatives\n",
        "\n",
        "Differences from rolling means\n",
        "\n",
        "### Anomaly Detection Methods\n",
        "#### Primary: High-Precision Isolation Forest\n",
        "Uses lower contamination range (0.05-0.2) for fewer false positives\n",
        "\n",
        "Optimizes contamination parameter specifically for precision\n",
        "\n",
        "Enhanced configuration: 150 estimators, smaller samples, feature subsetting\n",
        "\n",
        "Anti-overfitting measures: max_samples=128, max_features=0.7\n",
        "\n",
        "#### Secondary: Statistical Z-Score Detection\n",
        "Maintains Z-score threshold at 3.0 standard deviations\n",
        "\n",
        "Uses stricter range grouping with minimum 3 consecutive points\n",
        "\n",
        "Only keeps substantial anomaly ranges\n",
        "\n",
        "### Range Processing & Grouping\n",
        "Stricter range grouping: Maximum 5-point gaps between anomalies (was 10)\n",
        "\n",
        "Minimum length requirement: 3+ consecutive anomalies to form a range\n",
        "\n",
        "Selective range combination: Only keeps substantial ranges from both methods\n",
        "\n",
        "Conservative merging: Smaller merge distance (10 points)"
      ],
      "id": "8c58faf5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Extract true anomaly ranges from labels\n",
        "def extract_true_anomaly_ranges(labels):\n",
        "    \"\"\"Extract contiguous anomaly ranges from label array\"\"\"\n",
        "    labels = np.array(labels)\n",
        "    anomaly_indices = np.where(labels == 1)[0]\n",
        "\n",
        "    if len(anomaly_indices) == 0:\n",
        "        return []\n",
        "\n",
        "    ranges = []\n",
        "    start = anomaly_indices[0]\n",
        "    end = anomaly_indices[0]\n",
        "\n",
        "    for i in range(1, len(anomaly_indices)):\n",
        "        if anomaly_indices[i] == anomaly_indices[i-1] + 1:\n",
        "            end = anomaly_indices[i]\n",
        "        else:\n",
        "            ranges.append((start, end))\n",
        "            start = anomaly_indices[i]\n",
        "            end = anomaly_indices[i]\n",
        "\n",
        "    ranges.append((start, end))\n",
        "    return ranges\n",
        "\n",
        "# High Precision Isolation Forest Anomaly Detector (Z-score threshold = 3.0)\n",
        "class HighPrecisionIsolationForestDetector:\n",
        "    def __init__(self, contamination_range=(0.05, 0.2), random_state=42):  # REDUCED range\n",
        "        self.contamination_range = contamination_range  # Lower: 0.05-0.2\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.anomaly_windows = []\n",
        "\n",
        "    def create_enhanced_features(self, series, window_sizes=[10, 20, 50, 100]):\n",
        "        \"\"\"Enhanced feature engineering with multiple statistical features\"\"\"\n",
        "        series = np.array(series).flatten()  # Ensure 1D array\n",
        "        features = []\n",
        "\n",
        "        # Original series (reshape to 2D for stacking)\n",
        "        features.append(series.reshape(-1, 1))\n",
        "\n",
        "        # Multiple rolling window statistics\n",
        "        for window in window_sizes:\n",
        "            if len(series) >= window:\n",
        "                # Rolling statistics\n",
        "                roll_mean = pd.Series(series).rolling(window=window, center=True).mean().values.reshape(-1, 1)\n",
        "                roll_std = pd.Series(series).rolling(window=window, center=True).std().values.reshape(-1, 1)\n",
        "                roll_min = pd.Series(series).rolling(window=window, center=True).min().values.reshape(-1, 1)\n",
        "                roll_max = pd.Series(series).rolling(window=window, center=True).max().values.reshape(-1, 1)\n",
        "\n",
        "                # Handle NaN values\n",
        "                roll_mean = np.nan_to_num(roll_mean)\n",
        "                roll_std = np.nan_to_num(roll_std)\n",
        "                roll_min = np.nan_to_num(roll_min)\n",
        "                roll_max = np.nan_to_num(roll_max)\n",
        "\n",
        "                features.extend([roll_mean, roll_std, roll_min, roll_max])\n",
        "\n",
        "                # Z-score based on rolling statistics\n",
        "                z_score = (series.reshape(-1, 1) - roll_mean) / (roll_std + 1e-8)\n",
        "                features.append(z_score)\n",
        "\n",
        "                # Differences and changes\n",
        "                diff_from_mean = series.reshape(-1, 1) - roll_mean\n",
        "                features.append(diff_from_mean)\n",
        "\n",
        "        # Global statistics\n",
        "        global_mean = np.full((len(series), 1), np.mean(series))\n",
        "        global_std = np.full((len(series), 1), np.std(series))\n",
        "        global_z = (series.reshape(-1, 1) - global_mean) / (global_std + 1e-8)\n",
        "        features.extend([global_mean, global_std, global_z])\n",
        "\n",
        "        # Rate of change and derivatives\n",
        "        diff_1 = np.diff(series, prepend=series[0])\n",
        "        diff_2 = np.diff(diff_1, prepend=diff_1[0])\n",
        "        features.extend([diff_1.reshape(-1, 1), diff_2.reshape(-1, 1)])\n",
        "\n",
        "        # Combine features\n",
        "        feature_matrix = np.hstack([f for f in features if f is not None])\n",
        "        return feature_matrix\n",
        "\n",
        "    def find_anomaly_ranges_stricter(self, predictions, max_gap=5, min_length=3):\n",
        "        \"\"\"Stricter range grouping to reduce false positives\"\"\"\n",
        "        anomaly_indices = np.where(predictions == -1)[0]\n",
        "\n",
        "        if len(anomaly_indices) == 0:\n",
        "            return []\n",
        "\n",
        "        # Group anomalies with smaller allowed gaps\n",
        "        ranges = []\n",
        "        start = anomaly_indices[0]\n",
        "        end = anomaly_indices[0]\n",
        "        consecutive_count = 1\n",
        "\n",
        "        for i in range(1, len(anomaly_indices)):\n",
        "            if anomaly_indices[i] <= anomaly_indices[i-1] + max_gap:  # Smaller gap\n",
        "                end = anomaly_indices[i]\n",
        "                consecutive_count += 1\n",
        "            else:\n",
        "                # Only keep ranges with minimum length\n",
        "                if consecutive_count >= min_length:  # Minimum length requirement\n",
        "                    ranges.append((start, end))\n",
        "                start = anomaly_indices[i]\n",
        "                end = anomaly_indices[i]\n",
        "                consecutive_count = 1\n",
        "\n",
        "        # Only keep the last range if it meets minimum length\n",
        "        if consecutive_count >= min_length:\n",
        "            ranges.append((start, end))\n",
        "\n",
        "        return ranges\n",
        "\n",
        "    def statistical_anomaly_detection(self, series, z_threshold=3.0):  # KEEP: 3.0\n",
        "        \"\"\"Statistical method using Z-scores with threshold = 3.0\"\"\"\n",
        "        z_scores = np.abs((series - np.mean(series)) / (np.std(series) + 1e-8))\n",
        "        statistical_anomalies = np.where(z_scores > z_threshold)[0]\n",
        "\n",
        "        # Convert point anomalies to ranges with STRICTER grouping\n",
        "        stat_ranges = []\n",
        "        if len(statistical_anomalies) > 0:\n",
        "            start = statistical_anomalies[0]\n",
        "            end = statistical_anomalies[0]\n",
        "            consecutive_count = 1\n",
        "\n",
        "            for i in range(1, len(statistical_anomalies)):\n",
        "                if statistical_anomalies[i] <= statistical_anomalies[i-1] + 3:  # STRICTER: 5 to 3\n",
        "                    end = statistical_anomalies[i]\n",
        "                    consecutive_count += 1\n",
        "                else:\n",
        "                    # Only keep ranges with minimum length\n",
        "                    if consecutive_count >= 3:  # Minimum 3 consecutive points\n",
        "                        stat_ranges.append((start, end))\n",
        "                    start = statistical_anomalies[i]\n",
        "                    end = statistical_anomalies[i]\n",
        "                    consecutive_count = 1\n",
        "\n",
        "            if consecutive_count >= 3:  # Minimum 3 consecutive points\n",
        "                stat_ranges.append((start, end))\n",
        "\n",
        "        return stat_ranges\n",
        "\n",
        "    def optimize_contamination_for_precision(self, X, target_precision=0.7):\n",
        "        \"\"\"Optimize contamination parameter for better precision\"\"\"\n",
        "        best_contamination = self.contamination_range[0]\n",
        "        best_score = -1\n",
        "\n",
        "        contamination_values = np.linspace(self.contamination_range[0], self.contamination_range[1], 20)\n",
        "\n",
        "        for contamination in contamination_values:\n",
        "            try:\n",
        "                # Create features\n",
        "                X_features = self.create_enhanced_features(X)\n",
        "                X_scaled = self.scaler.fit_transform(X_features)\n",
        "\n",
        "                # Train Isolation Forest\n",
        "                model = IsolationForest(\n",
        "                    contamination=contamination,\n",
        "                    random_state=self.random_state,\n",
        "                    n_estimators=150,  # More trees for stability\n",
        "                    max_samples=128,   # Smaller samples for less overfitting\n",
        "                    max_features=0.7,  # Use subset of features\n",
        "                    n_jobs=-1\n",
        "                )\n",
        "                model.fit(X_scaled)\n",
        "\n",
        "                # Predict anomalies\n",
        "                predictions = model.predict(X_scaled)\n",
        "                pred_ranges = self.find_anomaly_ranges_stricter(predictions)\n",
        "\n",
        "                # Use anomaly count as precision proxy\n",
        "                anomaly_ratio = np.sum(predictions == -1) / len(predictions)\n",
        "                # Lower anomaly ratio typically means higher precision\n",
        "                precision_proxy = 1.0 - min(anomaly_ratio * 3, 0.9)  # Favor lower contamination\n",
        "\n",
        "                if precision_proxy > best_score:\n",
        "                    best_score = precision_proxy\n",
        "                    best_contamination = contamination\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return best_contamination\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"Fit and predict with precision optimization\"\"\"\n",
        "        try:\n",
        "            # Optimize contamination for precision\n",
        "            optimal_contamination = self.optimize_contamination_for_precision(X)\n",
        "            print(f\"Optimal contamination for precision: {optimal_contamination:.4f}\")\n",
        "\n",
        "            # Create enhanced features\n",
        "            X_features = self.create_enhanced_features(X)\n",
        "            X_scaled = self.scaler.fit_transform(X_features)\n",
        "\n",
        "            # Train Isolation Forest with precision-optimized parameters\n",
        "            self.model = IsolationForest(\n",
        "                contamination=optimal_contamination,\n",
        "                random_state=self.random_state,\n",
        "                n_estimators=150,\n",
        "                max_samples=128,  # Smaller for less overfitting\n",
        "                max_features=0.7, # Use subset of features\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            self.model.fit(X_scaled)\n",
        "\n",
        "            # Get Isolation Forest predictions with STRICTER range grouping\n",
        "            iso_predictions = self.model.predict(X_scaled)\n",
        "            iso_ranges = self.find_anomaly_ranges_stricter(iso_predictions, max_gap=5, min_length=3)\n",
        "\n",
        "            # Get statistical method predictions with Z-threshold = 3.0\n",
        "            stat_ranges = self.statistical_anomaly_detection(X, z_threshold=3.0)  # KEEP: 3.0\n",
        "\n",
        "            # Combine methods but be more selective\n",
        "            all_ranges = []\n",
        "\n",
        "            # Only add Isolation Forest ranges if they're substantial\n",
        "            for start, end in iso_ranges:\n",
        "                if (end - start) >= 2:  # Minimum 3 points\n",
        "                    all_ranges.append((start, end))\n",
        "\n",
        "            # Only add Z-score ranges if they're very clear\n",
        "            for start, end in stat_ranges:\n",
        "                if (end - start) >= 2:  # Minimum 3 points for Z-score\n",
        "                    all_ranges.append((start, end))\n",
        "\n",
        "            # Merge overlapping ranges with STRICTER criteria\n",
        "            if all_ranges:\n",
        "                all_ranges.sort()\n",
        "                merged_ranges = []\n",
        "                current_start, current_end = all_ranges[0]\n",
        "\n",
        "                for start, end in all_ranges[1:]:\n",
        "                    if start <= current_end + 10:  # Smaller merge distance\n",
        "                        current_end = max(current_end, end)\n",
        "                    else:\n",
        "                        # Only keep merged range if substantial\n",
        "                        if (current_end - current_start) >= 2:\n",
        "                            merged_ranges.append((current_start, current_end))\n",
        "                        current_start, current_end = start, end\n",
        "\n",
        "                if (current_end - current_start) >= 2:\n",
        "                    merged_ranges.append((current_start, current_end))\n",
        "                self.anomaly_windows = merged_ranges\n",
        "            else:\n",
        "                self.anomaly_windows = []\n",
        "\n",
        "            print(f\"Detected {len(self.anomaly_windows)} high-confidence anomaly ranges\")\n",
        "            print(f\"Isolation Forest ranges: {len(iso_ranges)}, Z-score ranges: {len(stat_ranges)}\")\n",
        "            return self.anomaly_windows\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in fit_predict: {e}\")\n",
        "            return self.fallback_detection_precision(X)\n",
        "\n",
        "    def fallback_detection_precision(self, X):\n",
        "        \"\"\"Fallback with high precision settings\"\"\"\n",
        "        from sklearn.ensemble import IsolationForest\n",
        "\n",
        "        # Use lower contamination for higher precision\n",
        "        model = IsolationForest(\n",
        "            contamination=0.08,  # Much lower\n",
        "            random_state=self.random_state,\n",
        "            n_estimators=100\n",
        "        )\n",
        "\n",
        "        predictions = model.fit_predict(X.reshape(-1, 1))\n",
        "        anomaly_indices = np.where(predictions == -1)[0]\n",
        "\n",
        "        # Stricter range grouping\n",
        "        if len(anomaly_indices) == 0:\n",
        "            return []\n",
        "\n",
        "        ranges = []\n",
        "        start = anomaly_indices[0]\n",
        "        end = anomaly_indices[0]\n",
        "        consecutive_count = 1\n",
        "\n",
        "        for i in range(1, len(anomaly_indices)):\n",
        "            if anomaly_indices[i] <= anomaly_indices[i-1] + 5:  # Stricter\n",
        "                end = anomaly_indices[i]\n",
        "                consecutive_count += 1\n",
        "            else:\n",
        "                if consecutive_count >= 3:  # Minimum length\n",
        "                    ranges.append((start, end))\n",
        "                start = anomaly_indices[i]\n",
        "                end = anomaly_indices[i]\n",
        "                consecutive_count = 1\n",
        "\n",
        "        if consecutive_count >= 3:\n",
        "            ranges.append((start, end))\n",
        "\n",
        "        return ranges\n",
        "\n",
        "# Updated student detection function for higher precision (Z-score threshold = 3.0)\n",
        "def student_detect_anomalies(series: np.ndarray) -> list:\n",
        "    \"\"\"\n",
        "    High-precision version using stricter parameters with Z-score = 3.0\n",
        "    \"\"\"\n",
        "    x = np.asarray(series, dtype=float)\n",
        "\n",
        "    if len(x) == 0:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        # Use the high-precision detector\n",
        "        detector = HighPrecisionIsolationForestDetector(contamination_range=(0.05, 0.2))\n",
        "        ranges = detector.fit_predict(x)\n",
        "        return ranges\n",
        "    except Exception as e:\n",
        "        print(f\"Error in student_detect_anomalies: {e}\")\n",
        "        return student_detect_anomalies_simple(series)\n",
        "\n",
        "# Simple fallback function (keep as backup)\n",
        "def student_detect_anomalies_simple(series: np.ndarray) -> list:\n",
        "    \"\"\"\n",
        "    Simple improved version with just higher contamination\n",
        "    \"\"\"\n",
        "    x = np.asarray(series, dtype=float)\n",
        "\n",
        "    if len(x) == 0:\n",
        "        return []\n",
        "\n",
        "    # Simple approach with significantly higher contamination\n",
        "    from sklearn.ensemble import IsolationForest\n",
        "\n",
        "    # Use much higher contamination\n",
        "    iso_forest = IsolationForest(\n",
        "        contamination=0.2,\n",
        "        random_state=42,\n",
        "        n_estimators=100\n",
        "    )\n",
        "\n",
        "    predictions = iso_forest.fit_predict(x.reshape(-1, 1))\n",
        "    anomaly_indices = np.where(predictions == -1)[0]\n",
        "\n",
        "    # Lenient range grouping with allowed gaps\n",
        "    if len(anomaly_indices) == 0:\n",
        "        return []\n",
        "\n",
        "    ranges = []\n",
        "    start = anomaly_indices[0]\n",
        "    end = anomaly_indices[0]\n",
        "\n",
        "    for i in range(1, len(anomaly_indices)):\n",
        "        if anomaly_indices[i] <= anomaly_indices[i-1] + 10:\n",
        "            end = anomaly_indices[i]\n",
        "        else:\n",
        "            ranges.append((start, end))\n",
        "            start = anomaly_indices[i]\n",
        "            end = anomaly_indices[i]\n",
        "\n",
        "    ranges.append((start, end))\n",
        "    return ranges\n",
        "\n",
        "# Keep the same evaluation function and main loop as before\n",
        "# Enhanced evaluation function with detailed range information\n",
        "def evaluate_anomaly_detection_formatted(true_ranges, predicted_ranges, tolerance=5, file_idx=None):\n",
        "    \"\"\"\n",
        "    Evaluate anomaly detection performance with exact formatting as requested\n",
        "    \"\"\"\n",
        "    # Convert point-level predictions\n",
        "    series_length = max(\n",
        "        max([end for _, end in true_ranges]) if true_ranges else 0,\n",
        "        max([end for _, end in predicted_ranges]) if predicted_ranges else 0,\n",
        "        0\n",
        "    ) + 1\n",
        "\n",
        "    # Create point-level arrays\n",
        "    true_point_labels = np.zeros(series_length, dtype=int)\n",
        "    pred_point_labels = np.zeros(series_length, dtype=int)\n",
        "\n",
        "    # Mark true anomalies\n",
        "    for start, end in true_ranges:\n",
        "        true_point_labels[start:end+1] = 1\n",
        "\n",
        "    # Mark predicted anomalies\n",
        "    for start, end in predicted_ranges:\n",
        "        pred_point_labels[start:end+1] = 1\n",
        "\n",
        "    # Calculate point-level metrics\n",
        "    true_positives = np.sum((true_point_labels == 1) & (pred_point_labels == 1))\n",
        "    false_positives = np.sum((true_point_labels == 0) & (pred_point_labels == 1))\n",
        "    false_negatives = np.sum((true_point_labels == 1) & (pred_point_labels == 0))\n",
        "\n",
        "    # Basic metrics\n",
        "    accuracy = (true_positives + (series_length - true_positives - false_positives - false_negatives)) / series_length\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Range-based metrics\n",
        "    range_true_positives = 0\n",
        "    range_false_positives = 0\n",
        "    range_false_negatives = 0\n",
        "\n",
        "    # Check each predicted range against true ranges\n",
        "    matched_true_ranges = set()\n",
        "    matched_pairs = []\n",
        "\n",
        "    for pred_start, pred_end in predicted_ranges:\n",
        "        matched = False\n",
        "        for i, (true_start, true_end) in enumerate(true_ranges):\n",
        "            # Check if predicted range overlaps with true range within tolerance\n",
        "            if (pred_start <= true_end + tolerance and pred_end >= true_start - tolerance):\n",
        "                if i not in matched_true_ranges:\n",
        "                    range_true_positives += 1\n",
        "                    matched_true_ranges.add(i)\n",
        "                    matched_pairs.append((i, (pred_start, pred_end), (true_start, true_end)))\n",
        "                    matched = True\n",
        "                    break\n",
        "\n",
        "        if not matched:\n",
        "            range_false_positives += 1\n",
        "\n",
        "    range_false_negatives = len(true_ranges) - len(matched_true_ranges)\n",
        "\n",
        "    range_precision = range_true_positives / (range_true_positives + range_false_positives) if (range_true_positives + range_false_positives) > 0 else 0\n",
        "    range_recall = range_true_positives / len(true_ranges) if len(true_ranges) > 0 else 0\n",
        "    range_f1 = 2 * (range_precision * range_recall) / (range_precision + range_recall) if (range_precision + range_recall) > 0 else 0\n",
        "\n",
        "    # Segment detection metrics\n",
        "    fully_detected = 0\n",
        "    partially_detected = 0\n",
        "    missed = 0\n",
        "    detection_details = []\n",
        "\n",
        "    for i, (true_start, true_end) in enumerate(true_ranges):\n",
        "        detected_points = 0\n",
        "        overlapping_ranges = []\n",
        "\n",
        "        for pred_start, pred_end in predicted_ranges:\n",
        "            # Calculate overlap\n",
        "            overlap_start = max(true_start, pred_start)\n",
        "            overlap_end = min(true_end, pred_end)\n",
        "            if overlap_start <= overlap_end:\n",
        "                overlap_points = overlap_end - overlap_start + 1\n",
        "                detected_points += overlap_points\n",
        "                overlapping_ranges.append((pred_start, pred_end, overlap_points))\n",
        "\n",
        "        total_points = true_end - true_start + 1\n",
        "        detection_ratio = detected_points / total_points if total_points > 0 else 0\n",
        "\n",
        "        if detection_ratio >= 0.8:  # 80% threshold for full detection\n",
        "            fully_detected += 1\n",
        "            detection_status = \"FULL\"\n",
        "        elif detection_ratio > 0:   # Any detection counts as partial\n",
        "            partially_detected += 1\n",
        "            detection_status = \"PARTIAL\"\n",
        "        else:\n",
        "            missed += 1\n",
        "            detection_status = \"MISSED\"\n",
        "\n",
        "        detection_details.append({\n",
        "            'true_range': (true_start, true_end),\n",
        "            'detection_ratio': detection_ratio,\n",
        "            'status': detection_status,\n",
        "            'overlapping_ranges': overlapping_ranges,\n",
        "            'detected_points': detected_points,\n",
        "            'total_points': total_points\n",
        "        })\n",
        "\n",
        "    segment_detection_rate = fully_detected / len(true_ranges) if len(true_ranges) > 0 else 0\n",
        "    overall_detection_rate = (fully_detected + partially_detected) / len(true_ranges) if len(true_ranges) > 0 else 0\n",
        "\n",
        "    # Print results in the exact format requested\n",
        "    print(f\"EVALUATION RESULTS - FILE {file_idx}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Display range information\n",
        "    print(\"Range Information:\")\n",
        "    print(f\"  True Ranges: {true_ranges} (count: {len(true_ranges)})\")\n",
        "    print(f\"  Predicted Ranges: {predicted_ranges} (count: {len(predicted_ranges)})\")\n",
        "    print()\n",
        "\n",
        "    # Display detection details for each true range\n",
        "    if detection_details:\n",
        "        print(\"Detection Details by Segment:\")\n",
        "        for i, detail in enumerate(detection_details):\n",
        "            status_symbol = \"✓\" if detail['status'] == \"FULL\" else \"~\" if detail['status'] == \"PARTIAL\" else \"✗\"\n",
        "            print(f\"  Segment {i}: {detail['true_range']} {status_symbol} {detail['status']} \"\n",
        "                  f\"({detail['detected_points']}/{detail['total_points']} points, \"\n",
        "                  f\"{detail['detection_ratio']:.1%})\")\n",
        "            if detail['overlapping_ranges']:\n",
        "                for pred_range in detail['overlapping_ranges']:\n",
        "                    print(f\"    → Overlap with predicted range {pred_range[0:2]}: {pred_range[2]} points\")\n",
        "        print()\n",
        "\n",
        "    print(\"Basic Metrics:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print()\n",
        "    print(\"Anomaly Statistics:\")\n",
        "    print(f\"  True Anomalies: {np.sum(true_point_labels)} points\")\n",
        "    print(f\"  Predicted Anomalies: {np.sum(pred_point_labels)} points\")\n",
        "    print(f\"  Detection Rate: {recall:.4f}\")\n",
        "    print()\n",
        "    print(\"Range-based Metrics:\")\n",
        "    print(f\"  Range Precision: {range_precision:.4f}\")\n",
        "    print(f\"  Range Recall:    {range_recall:.4f}\")\n",
        "    print(f\"  Range F1:        {range_f1:.4f}\")\n",
        "    print()\n",
        "    print(\"Point-level Performance:\")\n",
        "    print(f\"  True Positives:  {true_positives} points\")\n",
        "    print(f\"  False Positives: {false_positives} points\")\n",
        "    print(f\"  False Negatives: {false_negatives} points\")\n",
        "    print()\n",
        "    print(\"Segment Detection Metrics:\")\n",
        "    print(f\"  Total Anomaly Segments: {len(true_ranges)}\")\n",
        "    print(f\"  Fully Detected: {fully_detected}\")\n",
        "    print(f\"  Partially Detected: {partially_detected}\")\n",
        "    print(f\"  Missed: {missed}\")\n",
        "    print(f\"  Segment Detection Rate: {segment_detection_rate:.4f}\")\n",
        "    print(f\"  Overall Detection Rate: {overall_detection_rate:.4f}\")\n",
        "    print()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'true_positives': true_positives,\n",
        "        'false_positives': false_positives,\n",
        "        'false_negatives': false_negatives,\n",
        "        'range_precision': range_precision,\n",
        "        'range_recall': range_recall,\n",
        "        'range_f1': range_f1,\n",
        "        'fully_detected': fully_detected,\n",
        "        'partially_detected': partially_detected,\n",
        "        'missed': missed,\n",
        "        'segment_detection_rate': segment_detection_rate,\n",
        "        'overall_detection_rate': overall_detection_rate,\n",
        "        'true_ranges': true_ranges,\n",
        "        'predicted_ranges': predicted_ranges,\n",
        "        'detection_details': detection_details,\n",
        "        'matched_pairs': matched_pairs\n",
        "    }\n",
        "\n",
        "# Updated main evaluation loop with high-precision settings (Z-score threshold = 3.0)\n",
        "print(\"Starting HIGH-PRECISION Anomaly Detection Evaluation\")\n",
        "print(\"Key improvements for higher precision:\")\n",
        "print(\"- Contamination range: 0.05-0.2 (reduced from 0.1-0.4)\")\n",
        "print(\"- Z-score threshold: 3.0 (maintained)\")\n",
        "print(\"- Stricter range grouping (max_gap=5, min_length=3)\")\n",
        "print(\"- Anti-overfitting measures (more trees, smaller samples)\")\n",
        "print(\"- More selective range merging and combination\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "total_files = len(test_files)\n",
        "all_metrics = []\n",
        "detailed_results = []\n",
        "\n",
        "for idx, test_df in enumerate(test_files):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    try:\n",
        "        # Extract series and labels\n",
        "        series = test_df['Value'].values if 'Value' in test_df.columns else test_df.iloc[:, 0].values\n",
        "        labels = test_df['Labels'].values if 'Labels' in test_df.columns else test_df.iloc[:, 1].values\n",
        "\n",
        "        # Get true anomaly ranges\n",
        "        true_ranges = extract_true_anomaly_ranges(labels)\n",
        "\n",
        "        # Detect anomalies using HIGH-PRECISION student's function\n",
        "        predicted_ranges = student_detect_anomalies(series)\n",
        "\n",
        "        # Evaluate with formatted output\n",
        "        metrics = evaluate_anomaly_detection_formatted(true_ranges, predicted_ranges, file_idx=idx)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "        # Store detailed results\n",
        "        detailed_results.append({\n",
        "            'file_idx': idx,\n",
        "            'true_ranges': true_ranges,\n",
        "            'predicted_ranges': predicted_ranges,\n",
        "            'metrics': metrics\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {idx}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Add zero metrics for failed files\n",
        "        all_metrics.append({\n",
        "            'accuracy': 0,\n",
        "            'precision': 0,\n",
        "            'recall': 0,\n",
        "            'f1_score': 0,\n",
        "            'true_positives': 0,\n",
        "            'false_positives': 0,\n",
        "            'false_negatives': 0,\n",
        "            'range_precision': 0,\n",
        "            'range_recall': 0,\n",
        "            'range_f1': 0,\n",
        "            'fully_detected': 0,\n",
        "            'partially_detected': 0,\n",
        "            'missed': 0,\n",
        "            'segment_detection_rate': 0,\n",
        "            'overall_detection_rate': 0,\n",
        "            'true_ranges': [],\n",
        "            'predicted_ranges': [],\n",
        "            'detection_details': [],\n",
        "            'matched_pairs': []\n",
        "        })\n",
        "\n",
        "# Calculate overall summary statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"OVERALL SUMMARY ACROSS ALL FILES - HIGH-PRECISION VERSION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate basic metrics\n",
        "overall_accuracy = np.mean([m['accuracy'] for m in all_metrics])\n",
        "overall_precision = np.mean([m['precision'] for m in all_metrics])\n",
        "overall_recall = np.mean([m['recall'] for m in all_metrics])\n",
        "overall_f1 = np.mean([m['f1_score'] for m in all_metrics])\n",
        "\n",
        "# Calculate range statistics\n",
        "total_true_ranges = sum([len(m['true_ranges']) for m in all_metrics])\n",
        "total_predicted_ranges = sum([len(m['predicted_ranges']) for m in all_metrics])\n",
        "total_matched_ranges = sum([len(m['matched_pairs']) for m in all_metrics])\n",
        "\n",
        "# Calculate other metrics\n",
        "overall_range_precision = np.mean([m['range_precision'] for m in all_metrics])\n",
        "overall_range_recall = np.mean([m['range_recall'] for m in all_metrics])\n",
        "overall_range_f1 = np.mean([m['range_f1'] for m in all_metrics])\n",
        "\n",
        "total_true_positives = sum([m['true_positives'] for m in all_metrics])\n",
        "total_false_positives = sum([m['false_positives'] for m in all_metrics])\n",
        "total_false_negatives = sum([m['false_negatives'] for m in all_metrics])\n",
        "\n",
        "total_fully_detected = sum([m['fully_detected'] for m in all_metrics])\n",
        "total_partially_detected = sum([m['partially_detected'] for m in all_metrics])\n",
        "total_missed = sum([m['missed'] for m in all_metrics])\n",
        "total_segments = total_fully_detected + total_partially_detected + total_missed\n",
        "\n",
        "overall_segment_detection_rate = total_fully_detected / total_segments if total_segments > 0 else 0\n",
        "overall_detection_rate = (total_fully_detected + total_partially_detected) / total_segments if total_segments > 0 else 0\n",
        "\n",
        "print(\"Overall Basic Metrics:\")\n",
        "print(f\"  Accuracy:  {overall_accuracy:.4f}\")\n",
        "print(f\"  Precision: {overall_precision:.4f}\")\n",
        "print(f\"  Recall:    {overall_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {overall_f1:.4f}\")\n",
        "print()\n",
        "print(\"Overall Range Statistics:\")\n",
        "print(f\"  Total True Ranges: {total_true_ranges}\")\n",
        "print(f\"  Total Predicted Ranges: {total_predicted_ranges}\")\n",
        "print(f\"  Total Matched Ranges: {total_matched_ranges}\")\n",
        "print(f\"  Range Match Rate: {total_matched_ranges/total_true_ranges:.4f}\" if total_true_ranges > 0 else \"  Range Match Rate: 0.0000\")\n",
        "print()\n",
        "print(\"Overall Range-based Metrics:\")\n",
        "print(f\"  Range Precision: {overall_range_precision:.4f}\")\n",
        "print(f\"  Range Recall:    {overall_range_recall:.4f}\")\n",
        "print(f\"  Range F1:        {overall_range_f1:.4f}\")\n",
        "print()\n",
        "print(\"Overall Point-level Performance:\")\n",
        "print(f\"  True Positives:  {total_true_positives} points\")\n",
        "print(f\"  False Positives: {total_false_positives} points\")\n",
        "print(f\"  False Negatives: {total_false_negatives} points\")\n",
        "print()\n",
        "print(\"Overall Segment Detection Metrics:\")\n",
        "print(f\"  Total Anomaly Segments: {total_segments}\")\n",
        "print(f\"  Fully Detected: {total_fully_detected}\")\n",
        "print(f\"  Partially Detected: {total_partially_detected}\")\n",
        "print(f\"  Missed: {total_missed}\")\n",
        "print(f\"  Segment Detection Rate: {overall_segment_detection_rate:.4f}\")\n",
        "print(f\"  Overall Detection Rate: {overall_detection_rate:.4f}\")\n",
        "\n",
        "# File-by-file summary table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FILE-BY-FILE SUMMARY - HIGH-PRECISION VERSION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'File':<6} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'True Ranges':<12} {'Pred Ranges':<12} {'Fully Det.':<12} {'Part. Det.':<12} {'Missed':<8}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for idx, metrics in enumerate(all_metrics):\n",
        "    true_range_count = len(metrics['true_ranges'])\n",
        "    pred_range_count = len(metrics['predicted_ranges'])\n",
        "\n",
        "    print(f\"{idx:<6} {metrics['accuracy']:.4f}    {metrics['precision']:.4f}     {metrics['recall']:.4f}     {metrics['f1_score']:.4f}     \"\n",
        "          f\"{true_range_count:<11} {pred_range_count:<11} {metrics['fully_detected']:<11} {metrics['partially_detected']:<11} {metrics['missed']:<8}\")\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "# Detailed range information for each file\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED RANGE INFORMATION BY FILE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for result in detailed_results:\n",
        "    if result['metrics']['true_ranges'] or result['metrics']['predicted_ranges']:\n",
        "        print(f\"\\nFile {result['file_idx']}:\")\n",
        "        print(f\"  True Ranges: {result['true_ranges']} (count: {len(result['true_ranges'])})\")\n",
        "        print(f\"  Predicted Ranges: {result['predicted_ranges']} (count: {len(result['predicted_ranges'])})\")\n",
        "\n",
        "        # Show matching information\n",
        "        if result['metrics']['matched_pairs']:\n",
        "            print(f\"  Matched Pairs:\")\n",
        "            for match in result['metrics']['matched_pairs']:\n",
        "                true_idx, pred_range, true_range = match\n",
        "                print(f\"    True Range {true_idx} {true_range} ↔ Predicted {pred_range}\")\n",
        "\n",
        "print(\"\\nEvaluation completed for all files with high-precision detection methods!\")"
      ],
      "id": "5b87d0e3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/alex/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}